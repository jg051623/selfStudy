{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Lab_11_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtAPljHM5PtNs2Xoql08qT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iwreorNTokBu"
      },
      "outputs": [],
      "source": [
        "## CNN Model Enesemble with MNIST Data\n",
        "# CNN model 3개 각각 학습시킨 후, inference 시 vote / mean 등을 이용하여 힘을 합칠 예정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "6lNtLpHaotY5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. set hyper parameters\n",
        "lr = 0.001\n",
        "training_epochs = 1\n",
        "batch_size = 100\n",
        "\n",
        "# set checkpoint saving directory\n",
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'mnist_cnn_seq'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok = True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ],
      "metadata": {
        "id": "XgkKIfvmo8z0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. make a data pipelining\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6lnAZAio-H6",
        "outputId": "a43f15d6-7dbb-463c-d849-8b579757e3a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis = -1)  # for 4D shape\n",
        "test_images = np.expand_dims(test_images, axis = -1)  # for 4D shape\n",
        "\n",
        "#one hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "id": "kLwRpW74o_tW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size = 100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(batch_size)\n",
        "\n",
        "# shuffle : 고정된 buffer_size만큼 epoch 마다 이미지를 섞어서 오버피팅이 줄도록 도와줌"
      ],
      "metadata": {
        "id": "t_datYz2pA_6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. build a neural network model - Model Subclassing / functionalAPI(Sequential API도 사용 가능)\n",
        "class MNISTModel(tf.keras.Model) :\n",
        "  def __init__(self) :\n",
        "    super(MNISTModel, self).__init__()\n",
        "    self.conv1 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'SAME', activation = tf.nn.relu)\n",
        "    self.pool1 = keras.layers.MaxPool2D(padding = 'SAME')\n",
        "    self.conv2 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'SAME', activation = tf.nn.relu)\n",
        "    self.pool2 = keras.layers.MaxPool2D(padding = 'SAME')\n",
        "    self.conv3 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = 'SAME', activation = tf.nn.relu)\n",
        "    self.pool3 = keras.layers.MaxPool2D(padding = 'SAME')\n",
        "    self.pool3_flat = keras.layers.Flatten()\n",
        "    self.dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "    self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "    self.dense5 = keras.layers.Dense(units = 10)\n",
        "\n",
        "  def call(self,inputs, training=False) :\n",
        "    net = self.conv1(inputs)\n",
        "    net = self.pool1(net)\n",
        "    net = self.conv2(net)\n",
        "    net = self.pool2(net)\n",
        "    net = self.conv3(net)\n",
        "    net = self.pool3(net)\n",
        "    net = self.pool3_flat(net)\n",
        "    net = self.dense4(net)\n",
        "    net = self.drop4(net)\n",
        "    net = self.dense5(net)\n",
        "    return net"
      ],
      "metadata": {
        "id": "cHpfo8z_pCHu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "num_models = 3\n",
        "for m in range(num_models) :\n",
        "  models.append(MNISTModel())  # 인스턴스 3개 생성"
      ],
      "metadata": {
        "id": "PMhTRildpHo0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4,5 define a loss function & calculate a gradient \n",
        "def loss_fn(model, images, labels) :\n",
        "  logits = model(images, training = True) # Dropout 적용됨\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "  return loss\n",
        "\n",
        "\n",
        "def grad(model, image, labels) :\n",
        "  with tf.GradientTape() as tape :\n",
        "    loss = loss_fn(model, images, labels) \n",
        "  return tape.gradient(loss, model.variables) #loss 를 이 모델에 있는 모든 parameter에 대해서 미분한 값을 구해주세요"
      ],
      "metadata": {
        "id": "j77GT30XpP5x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## 변화가 있는 부분  \n",
        "# 6. select an optimizer - Adam.. etc\n",
        "# 7. define a metric for model's performance - accuracy etc\n",
        "# 8. (optional) make a checkpoint for saving\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
        "\n",
        "def evaluate(models, images, labels) :\n",
        "  predictions = tf.zeros_like(labels)  # model 3개의 결과 종합하기 위해서 만듦 / labels shape과 동일하게 \n",
        "  # tf.zeros_like : Creates a tensor with all elements set to zero.\n",
        "  for model in models :\n",
        "    logits = model(images, training=False) \n",
        "    predictions += logits        # 3개의 모델에서 나온 각각의 logits을 다 더하고 correct_prediction 이용\n",
        "  correct_prediction = tf.equal(tf.argmax(predictions,1), tf.argmax(labels,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "#tf.equal() 함수는 두 값이 동일하면 True, 다르면 False를 반환하는 함수입니다.\n",
        "#tf.cast() 함수는 True/False 형태의 값을 1과 0으로 바꾸어주는 함수입니다.\n",
        "\n",
        "checkpoints = []\n",
        "for m in range(num_models) :\n",
        "  checkpoints.append(tf.train.Checkpoint(cnn = models[m]))"
      ],
      "metadata": {
        "id": "aRoBLQN1phTW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변경 O\n",
        "# 9.  train an validate a neural network model\n",
        "\n",
        "for epoch in range(training_epochs) :\n",
        "  avg_loss = 0\n",
        "  avg_train_acc = 0\n",
        "  avg_test_acc = 0\n",
        "  train_step = 0\n",
        "  test_step = 0\n",
        "\n",
        "  for images, labels in train_dataset :\n",
        "    for model in models :\n",
        "      grads = grad(model, images, labels)\n",
        "      optimizer.apply_gradients(zip(grads, model.variables))\n",
        "      loss = loss_fn(model, images, labels)\n",
        "      avg_loss += loss/num_models   # 1/3(a+b) = 1/3*a + 1/3*b\n",
        "    acc = evaluate(models, images, labels)\n",
        "    avg_train_acc = avg_train_acc + acc\n",
        "    train_step += 1\n",
        "  \n",
        "  avg_loss = avg_loss / train_step\n",
        "  avg_train_acc = avg_train_acc / train_step\n",
        "  \n",
        "  for images, labels in test_dataset:\n",
        "    acc = evaluate(models, images, labels)        \n",
        "    avg_test_acc += acc\n",
        "    test_step += 1    \n",
        "  avg_test_acc = avg_test_acc / test_step   \n",
        "\n",
        "  print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "        'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "        'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "    \n",
        "  for idx, checkpoint in enumerate(checkpoints) :\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix+'-{}'.format(idx)) # epoch 한번 끝날때마다 모델 저장\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "skiBmfh5rFva",
        "outputId": "13148c15-1b9e-46d0-88d3-a09fd0baf37f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ebe0e73a00bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-833f5820ad58>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, image, labels)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loss 를 이 모델에 있는 모든 parameter에 대해서 미분한 값을 구해주세요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_ReluGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ReluGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu_grad\u001b[0;34m(gradients, features, name)\u001b[0m\n\u001b[1;32m  10719\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10720\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m> 10721\u001b[0;31m         _ctx, \"ReluGrad\", name, gradients, features)\n\u001b[0m\u001b[1;32m  10722\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10723\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pHOn2CpKsZJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}