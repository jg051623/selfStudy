{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Lab_10_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnXLnXO31jaZEi93ZGrJ5G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zlAjLLoqhnC8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image normalization \n",
        "def normalize(train_data, test_data) :\n",
        "  train_data = train_data.astype(np.float32) / 255.0\n",
        "  test_data = test_data.astype(np.float32) / 255.0\n",
        "  return train_data, test_data\n",
        "\n",
        "# load mnist with preprocessing\n",
        "def load_mnist() : \n",
        "  (train_data,train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  # in tensorflow input shape : (batch_size, height, width, channel)\n",
        "  train_data = np.expand_dims(train_data, axis = -1)  # (N,28,28) -> (N, 28, 28, 1) \n",
        "  test_data = np.expand_dims(test_data, axis = -1)  # (N,28,28) -> (N, 28, 28, 1) \n",
        "\n",
        "  train_data, test_data = normalize(train_data, test_data)  # 0~ 255 > 0~1\n",
        "\n",
        "  # label preprocessing\n",
        "  train_labels = to_categorical(train_labels, 10)  # (n,) -> (n,10) / one-hot encoding / 10 : class 개수\n",
        "  test_labels = to_categorical(test_labels, 10) \n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "t688E_Wkhn0P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network\n",
        "\n",
        "def flatten() :\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "# To make Fully connected layer\n",
        "def dense(channel,weight_init) :\n",
        "  return tf.keras.layers.Dense(units = channel, use_bias = True, kernel_initializer = weight_init) # units : output으로 나가는 channel 개수 use_bias : bias 사용 여부 kernel_initializer : weight initializer\n",
        "\n",
        "def relu() :\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "def batch_norm() :\n",
        "  return tf.keras.layers.BatchNormalization()"
      ],
      "metadata": {
        "id": "EPXPzA1Qhp3r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model(tf.keras.Model) : \n",
        "  def __init__(self, label_dim) :\n",
        "    super(create_model, self).__init__()\n",
        "    weight_init = tf.keras.initializers.glorot_uniform()  # Xavier initialization  / he_uniform() : he initialization\n",
        "    self.model = tf.keras.Sequential()   # layer을 층층이 쌓아나가는 것을 list에 계속 더해준다고 할 수 있음 / Sequential : list 자료 구조 type\n",
        "\n",
        "    self.model.add(flatten())   # (N,28,28,1) -> (n, 784)  / fully connected layer을 이용하기 때문에 flatten 시킴 / CNN 이라면 필요 없음\n",
        "\n",
        "    for i in range(2) : \n",
        "      # (N,784) > (N,256) > (N,256)\n",
        "      self.model.add(dense(256, weight_init))\n",
        "      self.model.add(batch_norm())              ## 일반적으로 layer > norm > activation 순서 // norm > activation > layer 순서도 있음\n",
        "      self.model.add(relu())\n",
        "\n",
        "    self.model.add(dense(label_dim,weight_init))  #(N,256) -> (N,10)\n",
        "  \n",
        "  def call(self, x, training=None, mask=None) :\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "NVAudaTjhycp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zZhjrX2sh57Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ViEjMTQEiYh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}